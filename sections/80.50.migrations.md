## Migrations

Migrations act as a way to mutate the schema and thus the database. Migrations act as a record of all changes made to the database and allow for making database changes in a consistent and repeatable manner.

There are multiple migration handlers which handle specific changes. Each type does directly affect the database; instead, they modify the schema, then the differences between the old and the new are calculated, and used to generate a set of transformation steps. This separation allows schemas to be generated without any need for a database, useful when performing automated tests.

Each handler is built in complete isolation from the rest of the system, only exposing essential methods.

### Migration Structure

Each migration comprises of a `name`, `timestamp`, `type` and `data`. The type references a specific migration handler such as `models/create` or `roles/destroy`. The data stores information specific to the given provider and can vary wildly, for instance, the `models/create` handler uses just a `name` field, whereas the `models/scopes/create` requires a name of the model, to add the scope to; a unique name, to identify the scope within the model; a set of parameters for the query; and the query itself defining how to identify the subset of data.

The name field is automatically generated and exists purely for displaying information to developers. Some migration handlers specify a way to generate a name if the handler does not specify then the name defaults to the name of the handler.

The timestamp field stores when the migration was created and is used to ensure the execution order of migrations is consistent.

### Storage

Migrations are stored inside the database (using the `Skeem-migrations` table) and also within the file system (in the migrations folder).

Migrations are stored in the file system so that they can be committed to a VCS (version control system) and therefore synced between different machines. Each migration is stored in a separate file to help reduce conflicts when different developers create multiple migrations. Each file contains a JSON object holding the migration type and the data. The downData nor the execution status is stored in the file, as not all developers would have executed the migrations.

Migration file names are in the format of `timestamp.name.json`. This naming scheme is done to help ensure migration files have unique names; there is no guarantee the migrations auto-generated name is unique, but it is unlikely that two developers would have created migrations which result in the same name at the same millisecond. Another advantage of including the timestamp first is that migrations appear correctly ordered within the folder - though not a necessity it does assist developers if they have to look at the migrations.

Initially, migrations were stored in the filesystem until executed, at which point they would have a row created - If a migration was in the database, then it had been executed. This pattern, however, proved to be confusing as to get a complete list of migrations the system first had to load those in the database, then read all the files and then eliminate files for which the timestamp and name were present in the database. There was also an issue of migrations loaded from files had different properties then those from the database - the database rows had a downData field and an ID field. Therefore the switch to storing all migrations in the database was made, allowing a full list of migrations to be obtained from a single query and used the file system purely for VCS abilities.

### Syncing

Before taking any action involving migrations, including executing or rollbacking back, synchronisation between the database and the filesystem is performed. Firstly, any migration file which does not have a corresponding row is new migrations created by other developers and therefore have a row created.

Next, rows without an associated file are deleted, as the migrations must have been removed. If one of these migrations has been executed, then an error is thrown as the system cannot remove the migration as it would break the ability to rollback.

Finally, all other migrations (they exist in both the file system and the database) have their data compared to ensure they are identical. If they are not, then the data from the filesystem takes presidents. If however, the database row was marked as executed, an error is thrown as once again changing the data could prevent rollbacks from functioning correctly.

### Running Migrations

Running migrations first loads the existing schema. Executing migrations get given and mutate this schema.

The first step in running a migration is to load the migrations handler. This handler then gets given the migrations data, the schema, as well as access to a general context object which stores application configuration as well as functions to assist with logging and database access.

Despite each handler being completely free to perform any actions they want to the schema, in general, they all follow a very similar pattern. There is no certainty that the passed data will contain the correct information or even be the correct type. Therefore, handler first type checks the data to ensure it is of the expected format and contains all the relevant information. For example, the `models/create` handle first checks to see if the data contains, exclusively, a name property. Then this name is checked to be a string, only containing letters and underscores and is not prefixed with `skeem-` (this is a reserved prefix). If these checks fail, a `migrationValidation` error is thrown along with the message of precisely what is wrong. The migration system is then free to act on this error as it chooses, if creating a new migration then the system will prompt the user to amend the specified data or aborting the process if currently executing migrations.

If the data is correct, then the handler will modify the schema, mutating it as needed.

After repeating this procedure for all pending migrations, the new schema is saved, marking the migrations as executed.

### Database Diffing

Obtaining a list of change steps must occur to mutate the database after running the migrations and producing a new schema.

The first step is to assess the differences by comparing the new schema to the old schema. The models and providers only exist in the abstract, as opposed to the db property, which is backed by database tables. Therefore, it is only the db property of the schema that requires the creation of a  difference.

The next step in the diffing process is to separate the new, the removed and which have _potentially_ updated tables. The name field of the table is used to link the old and the new schema. If a name exists in the old schema but not in the new, then the table is marked as deleted. Similarly, if a name exists in the new schema but not the old, it is marked as created. If the name exists in both, then the table is marked as potentially updated and undergoes a further diff.

For each new table, the appropriate `CREATE TABLE` SQL query is generated and appended to a list of all pending database queries. Likewise, for each removed table, a `DROP TABLE` query is produced and appended to the list.

For each updated table, every column is compared between the new and the old, and a separation between those that have been updated, created and removed is formed using a similar method as when comparing the tables. An array of column changes is now generated using the following rules:

- If the column is new, then an `ADD COLUMN` command is used.
- Else if the column was removed, then a `DROP COLUMN` command is used.
- Else if there are any changes, then an `CHANGE COLUMN` command is used.

Finally these column alterations are concatinated into a single `ALTER TABLE` query and added to the list.

```{.sql caption="The format of an ALTER TABLE query"}
ALTER TABLE {tableNow.name} {column changes}
```

The list of SQL commands is then executed by first initialising a transaction within the database. This transaction means if an error occurs within the mutate steps, the database can be fully restored to before the mutations. Without this then the schema could become out of sync with the database. The list of SQL statements is the run sequentially. After each step has been executed the schema in the database is replaced by the new schema. Finally, a commit message is sent to Postgres informing it to proceed with the mutations. By updating the schema within the same transaction ensures synchronicity between the tables and the schema.

### Rolling Back

Migrations all can be reversed.

When a migration is executed, it has the option of returning some data. This data will be passed back to the migration when rolling back.

For example, this data is used when creating an association. The migration will return the name of the added attribute and the name of the created joining table. With this information, the migration is then able to fully undo any effects it had thus restoring the previous schema.

Rolling back is not guaranteed to revert the database completely to its state before the migration because some migrations such as deleting an attribute are lossy and thus are not purely reversible. Instead, it merely guarantees that the structure of the database will be identical.
