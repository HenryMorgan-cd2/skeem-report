## Migrations

Migrations act as a way to mutate the schema and thus the database. Migrations act as a record of all changes made to the database, and allow for changes to be made in a consistent and repeatable manner.

There are multiple migration handlers which handle specific changes. Each type does directly effect the database instead they modify the schema, then the differences between the old and the new are calculated and a set of transformation steps are generated. This separation allows schemas to be generated without any need for a database, useful when performing automated tests.

### Migration Structure

Each migration is comprised of a `name`, `timestamp`, `type` and `data`. The type references a specific migration handler such as `models/create` or `roles/destroy`. The data stores information specific to the given provider and can vary wildly, for instance, the `models/create` handler uses just a `name` field, whereas the `models/scopes/create` requires a the name of the model, to add the scope to; a unique name, to identify the scope within the model; a set of parameters to be passed the query; and the query itself which defines how to identify the subset of data.

The name is field is automatically generated and exists purely to for displaying information to developers. Some migration handlers specify a way to generate a name, if the handler does not specify then the name defaults to the name of the handler.

The timestamp field stores when the migration was created. It is used to ensure the order in which migrations are executed remains consistent.

### Storage

Migrations are stored both in the database (in the `skeem-migrations` table) and in the file system (in the migrations folder).

Migrations are stored in the file system so that they can be committed to a VCS (version control system) and therefore synced between different machines. Each migration is stored in a separate file to help reduce conflicts when multiple migrations are created by different developers. Each file contains a json object holding the migration type and the data. The downData nor the execution status is stored in the file, as not all developers would have executed the migrations.

Migration file names are in the format of `timestamp.name.json`. This done to help ensure migration files have unique names, there is no guarantee the the migrations auto-generated name is unique but it is unlikely that two developers would have created migrations which result in the same name at the exact same millisecond. Another advantage of including the timestamp first is that migrations appear in the correct order within the folder - though not a necessity it does assist developers if they have to look at the migrations.

Initially migrations were stored in the filesystem until they were executed, at which point they would have a row created. If a migration was in the database then it had been executed. This, however, proved to be confusing as to get a complete list of migrations you first had to load those in the database, then read all the files and then eliminate files for which the timestamp and name was present in the database. There was also an issue of migrations loaded from files had different properties then those form the database - the database rows had a downData field and an ID field. I therefore switched to storing all migrations in the database allowing a full list of migrations to be obtained from a single query and used the file system purely for VCS abilities.

### Syncing

Before any action involving migrations is taken including execution and a roll back, a sync is performed between the migrations in the database and those stored in the filesystem. Firstly, any migration file which does not have a corresponding row are new migrations created by other developers and therefore have a row created.

Next any rows which do not of a file associated are found, the migrations must have been removed and so should be deleted from the database. If one of these migrations has been executed then an error is throw as the system cannot remove the migration as it would break the ability to rollback.

Finally all other migrations (they exist in both the file system and the database) have their data compared to ensure they are identical. If they are not then the data from the filesystem takes presidents. If the database row has been executed however, an error is throw as once again changing the data could prevent rollbacks.

### Running Migrations

Before running migrations the existing schema is loaded. Over the course of running the migrations this schema will be mutated.

The first step in running a migration is to load the migrations handler. This handler then gets given the migrations data, the schema, as well as access to a general context object which stores application configuration as well as functions to assist with logging and database access.

Despite each handler being completely free to perform any actions they want to the schema, in general, they all follow a very similar pattern. Each handler is built in complete isolation from the rest of the system, only exposing key methods, the data being passed in has no insurance of containing the correct information or being the correct type. Therefore, handler first type checked the data to ensure it is of the expected format and contains all the relevant information. For example, the `models/create` handle first checks to see if the data contains, exclusively, a name property. Then this name is checked to be a string, only containing letters and underscores and is not prefixed with `skeem-` (this is a reserved prefix). If any of these checks fail a `migrationValidation` error is thrown along with the message of specifically what is wrong. The migration system is then free to act on this error as it chooses, if creating a new migration then the system will prompt the user to amend the data they specified, or if migrations are being executed then the process is aborted.

If the data is correct then the handler will modify the schema, mutating it as needed.

The procedure is repeated for all pending migrations. If all migrations were executed successfully then the new schema is saved to the database and the migrations are marked as executed.

### Database Diffing

After a new schema has been produced, a list of change steps must be realized in order to mutate the existing database. This happens are migrations are run or when the application is initialized. In the latter case the empty schema is used as the old schema.

The first step of this process is to compare the new schema and the old one in order to find what is actually different. Because the models and providers only exist in the abstract, as opposed to the db property which is backed by database tables, only the db of the schema is diffed.

The first step in diffing the dbs is to isolate which tables are new, which have been removed and which have been _potentially_ updated. The name field of the table is used to link the old and the new schema. If a name exists in the old schema but not in the new, then the table is marked as deleted. Similarly, if a name exists in the new schema but not the old it is marked as created. If the name exists in both then the table is marked as potentially updated and undergoes a further diff.

For each new table the appropriate `CREATE TABLE` SQL query is generated and appended to a list of all pending database queries. Like wise for each removed table a `DROP TABLE` query is produced and appended to the list.

For each updated table each column

The list of sql commands is then executed. To do this, first, a new transaction is created within the database. This means if an error occurs within the mutate steps the database can be fully restored to prior to the mutations. Without this then the schema could become out of sync with the database. The list of sql statements is the run sequentially. After each step has been executed the schema in the database is replaced by the new schema. Finally, a commit message is sent to Postgres informing it to proceed with the mutations. By updating the schema within the same transaction ensures synchronicity between the tables and the schema.

### Rolling Back

Migrations all have the ability to be reversed.

When a migration is executed it has the option of returning some data. This data will be passed back to the migration when rolling back. This is used, for example, when creating an association the migration will return: the name of the added attribute and the name of the created joining table. With this information the migration is then able to fully undo any effects it had thus restoring the previous schema.

Rolling back is not guaranteed to revert the database completely to its state prior to the migration, instead it simply guarantees the structure of the database will be identical. This is because some migrations such as deleting an attribute are lossy in nature and thus are not purely reversible.
